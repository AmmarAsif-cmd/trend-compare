# Testing Guide - Context-Aware Peak Explanations

Complete guide to testing the context-aware peak explanation functionality.

---

## ğŸš€ Quick Start

### Prerequisites
```bash
# Install dependencies
npm install -D vitest tsx @anthropic-ai/sdk
```

### Run All Tests
```bash
# Option 1: Vitest (recommended)
npm run test

# Option 2: Test script
npx tsx scripts/test-peak-explanations.ts

# Option 3: Specific test file
npm run test __tests__/context-aware-verification.test.ts
```

---

## ğŸ“ Test Files

### 1. Mock Data (`__tests__/mock-data.ts`)
Contains all test fixtures:
- Wikipedia event responses
- GDELT news article responses
- AI verification responses
- 5 comprehensive test scenarios

### 2. Unit Tests (`__tests__/context-aware-verification.test.ts`)
Vitest test suite with:
- 51 unit tests
- Mock API responses
- Integration tests for full scenarios
- Assertion-based validation

### 3. Test Runner (`scripts/test-peak-explanations.ts`)
Comprehensive test runner that:
- Runs all test suites
- Generates detailed reports
- Shows pass/fail statistics
- Can be run standalone

### 4. Expected Results (`TEST_RESULTS_EXPECTED.md`)
Documentation showing:
- Expected test output
- Test coverage details
- Success criteria
- Failure scenarios to watch for

---

## ğŸ§ª What Gets Tested

### Test Suite 1: Ambiguous Keyword Detection (12 tests)
Tests `isAmbiguousKeyword()` function:

```typescript
isAmbiguousKeyword('apple')     // â†’ true âœ“
isAmbiguousKeyword('java')      // â†’ true âœ“
isAmbiguousKeyword('python')    // â†’ true âœ“
isAmbiguousKeyword('iPhone')    // â†’ false âœ“
```

**Validates**: System correctly identifies 20+ ambiguous keywords

---

### Test Suite 2: Category Auto-Detection (10 tests)
Tests `suggestCategory()` function:

```typescript
suggestCategory('iPhone', 'Android')        // â†’ 'technology' âœ“
suggestCategory('Pizza', 'Burger')          // â†’ 'food' âœ“
suggestCategory('Netflix', 'Disney Plus')   // â†’ 'entertainment' âœ“
suggestCategory('Messi', 'Ronaldo')         // â†’ 'sports' âœ“
```

**Validates**: System auto-detects comparison category correctly

---

### Test Suite 3: Context-Based Event Filtering (7 tests)
Tests `verifyEventWithContext()` and filtering:

```typescript
// Scenario: iPhone vs Android (tech context)
Event: "Apple unveils iPhone 15"
â†’ Relevance: 98%, Context Match: YES âœ“ INCLUDED

Event: "Apple fruit harvest"
â†’ Relevance: 5%, Context Match: NO âœ“ FILTERED

// Scenario: Oranges vs Apples (food context)
Event: "Apple unveils iPhone 15"
â†’ Relevance: 8%, Context Match: NO âœ“ FILTERED

Event: "Apple fruit harvest"
â†’ Relevance: 92%, Context Match: YES âœ“ INCLUDED
```

**Validates**: Events filtered correctly based on comparison context

---

### Test Suite 4: Interpretation Accuracy (5 tests)
Tests interpretation strings:

```typescript
// iPhone vs Android context
Interpretation: "Apple Inc. (technology company)" âœ“

// Oranges vs Apples context
Interpretation: "Apple (fruit)" âœ“

// Java vs Python context
Interpretation: "Java (programming language)" âœ“
```

**Validates**: AI provides clear, accurate interpretations

---

### Test Suite 5: AI Response Quality (11 tests)
Tests all mock AI responses:

```typescript
Response validation:
âœ“ Relevance score: 0-100
âœ“ Interpretation: non-empty string
âœ“ Reasoning: > 10 characters
âœ“ Confidence: 0-100
âœ“ Context match: boolean
âœ“ Logic: high relevance = context match
```

**Validates**: All AI responses have correct structure

---

## ğŸ¯ Test Scenarios

### Scenario 1: Apple (Tech vs Food)

**Test**: Same keyword, different contexts

```typescript
// Context 1: iPhone vs Android (TECH)
Peak: "Apple" on 2023-09-12
Expected: Show iPhone 15 event âœ“
Filter:   Apple harvest âœ—

// Context 2: Oranges vs Apples (FOOD)
Peak: "Apple" on 2023-09-12
Expected: Show apple harvest âœ“
Filter:   iPhone 15 event âœ—
```

**Result**: âœ“ Different events for same peak based on context

---

### Scenario 2: Java (Programming vs Geography vs Coffee)

**Test**: Keyword with 3+ meanings

```typescript
// Context: Java vs Python (PROGRAMMING)
Peak: "Java" on 2023-03-21

Events found:
1. "Oracle releases Java 20" â†’ 96%, INCLUDED âœ“
2. "Java island earthquake" â†’ 3%, FILTERED âœ—
3. "Starbucks Java coffee" â†’ 12%, FILTERED âœ—
```

**Result**: âœ“ Only programming events shown

---

### Scenario 3: Tesla (Car vs Scientist)

**Test**: Company vs person disambiguation

```typescript
// Context: Model 3 vs Bolt (AUTOMOTIVE)
Peak: "Tesla" on 2023-07-19

Events found:
1. "Tesla Q2 deliveries" â†’ 94%, INCLUDED âœ“
2. "Nikola Tesla museum" â†’ 15%, FILTERED âœ—
```

**Result**: âœ“ Only car company events shown

---

### Scenario 4: Python (Programming vs Animal)

**Test**: Tech vs nature context

```typescript
// Context: Snakes vs Lizards (ANIMALS)
Peak: "Python" on 2023-06-05

Events found:
1. "Python 3.12 beta" â†’ 8%, FILTERED âœ—
2. "17-foot python captured" â†’ 88%, INCLUDED âœ“
```

**Result**: âœ“ Only animal events shown

---

## ğŸ“Š Success Criteria

### All Tests Must Pass (51/51)
```
âœ“ Ambiguous detection: 12/12
âœ“ Category detection: 10/10
âœ“ Event filtering: 7/7
âœ“ Interpretation: 5/5
âœ“ AI responses: 11/11
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 51/51 (100%) âœ“
```

### Zero Failures
```
âœ— Failed: 0
```

### Specific Validations
```
âœ“ No false positives (wrong events included)
âœ“ No false negatives (correct events filtered)
âœ“ All interpretations accurate
âœ“ All categories correct
```

---

## ğŸ”§ Running Individual Test Suites

### Test Ambiguous Keywords Only
```typescript
import { isAmbiguousKeyword } from './lib/context-aware-peak-verification';

console.log(isAmbiguousKeyword('apple'));    // true
console.log(isAmbiguousKeyword('java'));     // true
console.log(isAmbiguousKeyword('iPhone'));   // false
```

### Test Category Detection Only
```typescript
import { suggestCategory } from './lib/context-aware-peak-verification';

console.log(suggestCategory('iPhone', 'Android'));  // 'technology'
console.log(suggestCategory('Pizza', 'Burger'));    // 'food'
```

### Test Full Verification (with mocks)
```typescript
import { verifyEventWithContext } from './lib/context-aware-peak-verification';

const result = await verifyEventWithContext(
  {
    title: "Apple unveils iPhone 15",
    description: "...",
    date: new Date('2023-09-12'),
    source: "Wikipedia"
  },
  'Apple',
  { termA: 'iPhone', termB: 'Android' },
  new Date('2023-09-12')
);

console.log(result.interpretation);  // "Apple Inc. (technology company)"
console.log(result.contextMatch);    // true
console.log(result.relevanceScore);  // 98
```

---

## ğŸ› Debugging Failed Tests

### If a test fails:

**1. Check which test failed**
```bash
npm run test -- --reporter=verbose
```

**2. Check expected vs actual**
```
Test: Apple in tech context
Expected: Apple Inc. (technology company)
Actual: Apple (fruit)
â†’ Problem: Wrong interpretation
```

**3. Verify mock data**
Check `__tests__/mock-data.ts`:
- Are mock responses correct?
- Do they match test expectations?

**4. Check AI prompt logic**
Check `lib/context-aware-peak-verification.ts`:
- Is prompt including comparison context?
- Is parsing response correctly?

**5. Run single test**
```bash
npm run test -- -t "Apple in tech context"
```

---

## ğŸ“ˆ Performance Benchmarks

### Expected Performance

```
Test execution time: < 2 seconds
Memory usage: < 100MB
API calls (mocked): 0
Coverage: 100% of context functions
```

### If tests are slow:

1. **Check API mocking**: Real API calls will slow tests
2. **Check data fixtures**: Too much mock data?
3. **Check async operations**: Awaiting too many promises?

---

## âœ… Pre-Deployment Checklist

Before deploying to production:

- [ ] All 51 tests passing
- [ ] Zero failures
- [ ] Mock data covers all scenarios
- [ ] Real API key set for integration tests
- [ ] Test on staging environment
- [ ] Verify with real Wikipedia/GDELT APIs
- [ ] Check AI verification costs
- [ ] Monitor first 100 real comparisons

---

## ğŸŠ Success Output

When all tests pass, you'll see:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      TEST RESULTS                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Total Tests: 51
âœ“ Passed: 51 (100%)
âœ— Failed: 0

ğŸ‰ ALL TESTS PASSED! ğŸ‰

The context-aware verification system is working correctly!
```

---

## ğŸš€ Next Steps After Tests Pass

1. **Integration Testing**: Test with real Wikipedia/GDELT APIs
2. **User Testing**: A/B test with real users
3. **Monitoring**: Track accuracy in production
4. **Iteration**: Improve based on real-world results

---

## ğŸ“ Troubleshooting

### Tests won't run
```bash
# Install missing dependencies
npm install -D vitest tsx @anthropic-ai/sdk

# Clear cache
rm -rf node_modules/.vite
npm run test -- --no-cache
```

### Mock API not working
```bash
# Verify mock is imported
import { vi } from 'vitest';

# Check vi.mock() is at top of test file
vi.mock('@anthropic-ai/sdk', ...)
```

### TypeScript errors
```bash
# Check tsconfig.json includes test files
{
  "include": ["**/*.ts", "**/*.tsx"]
}
```

---

**Ready to test? Run: `npm run test`** ğŸ§ª
